{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119e3475",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "### A selection of interesting solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b052147",
   "metadata": {},
   "source": [
    "#### Task 1: Exhaustive error handling and np.delete to clip array\n",
    "\n",
    "**Note from Teo**: *In contrast to the solution I provided, it is, indeed, more professional to extend functions with **if+raise** and then write the **try+except** in the actual application (that would be in this case the next cell in the assignment notebook, where the array is being clipped).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_mat(arr):\n",
    "    \"\"\"Simple function to strip down a 2-D matrix with at least 3 rows and 3 columns to its inner matrix, by deleting the outer rows and columns\"\"\"\n",
    "\n",
    "    # At least check if the argument is no text or plain number\n",
    "    if type(arr) == str or type(arr) == float or type(arr) == int:\n",
    "        raise Exception(\"Given argument is no array!\")\n",
    "   \n",
    "    # Litte type cast, not perfect\n",
    "    # Check for correct dimension\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2:\n",
    "        raise Exception(\"Given matrix is no 2-D matrix!\")\n",
    "    \n",
    "    # Check number of matrix rows and columns\n",
    "    nrow, ncol = arr.shape\n",
    "    if (nrow or ncol) < 3  :\n",
    "        raise Exception(\"Given matrix has too few columns or rows!\")\n",
    "    \n",
    "    arr = np.delete(arr,0,0)    # delete first row\n",
    "    arr = np.delete(arr,-1,0)   # delete last row\n",
    "    arr = np.delete(arr,0,1)    # delete first column \n",
    "    \n",
    "    return np.delete(arr,-1,1)  # delete last column\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f850c",
   "metadata": {},
   "source": [
    "#### Task 2: Very compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr=np.random.normal([1, -2], [2, 0.5], (10000, 2))\n",
    "plt.hist(rand_arr[:,0], bins = 20)\n",
    "plt.hist(rand_arr[:,1], bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd802bcc",
   "metadata": {},
   "source": [
    "#### Task 2: Dynamically extending the random array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e262cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr = np.random.normal(1,2, size = (10000,2))\n",
    "rand_arr[:,1] = np.random.normal(-2,0.5, size = 10000)\n",
    "\n",
    "#The 2 sources from where I've learned a lot about Normal (Gaussian) Distribution\n",
    "#Source 1: https://www.w3schools.com/python/numpy/numpy_random_normal.asp\n",
    "#Source 2: https://sparkbyexamples.com/numpy/how-to-use-numpy-random-normal-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033af9cd",
   "metadata": {},
   "source": [
    "#### Task 3: Inner function for transforming one single point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_to_polar(arr: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Converts the given array of cartesian coordinates into polar coordinates.\n",
    "    array must be of shape (x,2)\n",
    "    \n",
    "    :param arr: Array of cartesian coordinates\n",
    "    :returns  : Array of polar coordinates\n",
    "    \"\"\"\n",
    "    if arr.shape[1] != 2:\n",
    "        raise ValueError(\"Array must be of shape (x, 2)\")\n",
    "    \n",
    "    def _to_polar(x,y):\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        phi = np.arctan(y/x)\n",
    "        \n",
    "        return r, phi\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        x = arr[i, 0]\n",
    "        y = arr[i, 1]\n",
    "        \n",
    "        arr[i, 0], arr[i, 1] = _to_polar(x,y)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557aee24",
   "metadata": {},
   "source": [
    "#### Task 3: Complex Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7eca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/20924085/python-conversion-between-coordinates\n",
    "import cmath\n",
    "\n",
    "array = np.random.rand(10,2)\n",
    "\n",
    "for i in range(len(array)):\n",
    "    input_num = complex(array[i][0], array[i][1]) \n",
    "    r, phi = cmath.polar(input_num)\n",
    "    array[i][0] = r\n",
    "    array[i][1] = phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4271f01",
   "metadata": {},
   "source": [
    "#### Task 3: Checking if the transformatio was right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()  \n",
    "matrix=(100-1)* rng.random(size=(10, 2))+1\n",
    "\n",
    "matrix[:,0]  # x coordinates\n",
    "matrix[:,1]  # y coordinates\n",
    "r=np.sqrt(matrix[:,0]**2 + matrix[:,1]**2)\n",
    "phi=np.arctan(matrix[:,1]/matrix[:,0])\n",
    "# this is the converted matrix:\n",
    "polarmatrix= np.column_stack((r, phi))\n",
    "\n",
    "# validate the correctness of the matrix transformation \n",
    "# by checking the 1st Point with the cmath polar function:\n",
    "print(\"r_1 with own transformation: \", r[0])\n",
    "print(\"phi_1 with own transformation: \", phi[0])\n",
    "\n",
    "import cmath\n",
    "matrix_xy_point1 = complex(matrix[0,0], matrix[0,1]) # stored as 1+2j\n",
    "r, phi = cmath.polar(matrix_xy_point1)\n",
    "print(\"r_1 with cmath: \",r)\n",
    "print(\"phi_1 with cmath: \",phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe45b8d",
   "metadata": {},
   "source": [
    "#### Task 3: Optional parameter for angle in degrees or radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_coordinates(x, degree = False):\n",
    "    \"\"\"\n",
    "    This function transforms given cartesian coordinates to polar coordinates. The angle is given in radians. If you want to have it in degrees just add degree = True\n",
    "    Input:  Array of dimension [n,2] with [:,0] being the x-coordinate and [:,1] being the y-coordinate.\n",
    "            degree (bool): -> if result should be in degrees or radians. \n",
    "    Output: Array of dimention [n,2] with [:,0] being the radius and [:,1] being the angle.\n",
    "    \"\"\"\n",
    "    r = np.sqrt(x[:,0]**2 + x[:,1]**2)\n",
    "    phi = np.arctan2(x[:,1], x[:,0])\n",
    "    if degree:\n",
    "        phi = phi/ (np.pi  /180)\n",
    "    return np.column_stack((r,phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98abf2",
   "metadata": {},
   "source": [
    "#### Task 4: Extract column, then describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/zuwendungen-berlin.csv.gz\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "print(df['Betrag'].describe(percentiles=[0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20584a05",
   "metadata": {},
   "source": [
    "#### Task 4: Dropping unnecessary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"..\\data\\zuwendungen-berlin.csv.gz\")\n",
    "stats = data.describe()\n",
    "stats.drop([\"25%\", \"75%\"], 0 , inplace=True)\n",
    "result= stats[\"Betrag\"].values.tolist()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc0b7f",
   "metadata": {},
   "source": [
    "#### Task 4: Statistics through aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (\n",
    "        df['Betrag'].agg(['count','mean', 'std', 'min','median','max'])\n",
    "       )\n",
    "print(out.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09cba2",
   "metadata": {},
   "source": [
    "#### Task 5: Lambda-Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(\"Name\")\n",
    "dff = grouped_df.apply(lambda d: d[\"Betrag\"].sum()==250).reset_index()\n",
    "dff[dff[0] == True][\"Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e831b49",
   "metadata": {},
   "source": [
    "#### Task 5: dataframe.filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e16a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df.groupby('Name')\n",
    "dataframe2 = dataframe.filter(lambda x: x.Betrag.sum() == 250)\n",
    "print(dataframe2['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62a3c3",
   "metadata": {},
   "source": [
    "#### Task 7: Regular Expressions to deal with white spaces in Ubahn labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e11668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"data\", \"zuwendungen-berlin.csv.gz\"))\n",
    "df['Ubahn'] = \"\"\n",
    "\n",
    "df_Verkehr = df[(df.Politikbereich == \"Verkehr\")]\n",
    "\n",
    "regex_pattern = \"U\\s?\\d\" #U1, U 1, U2, U 2, U3, U 3....etc\n",
    "\n",
    "for i in df_Verkehr.index:\n",
    "    tempZweck = df_Verkehr.loc[i,'Zweck']\n",
    "    if type(tempZweck) is str:\n",
    "        matches = re.findall(regex_pattern, tempZweck)\n",
    "        df_Verkehr.loc[i,'Ubahn'] = matches[0].strip().replace(\" \", \"\") if len(matches) > 0 else \"\"\n",
    "\n",
    "df_Verkehr = df_Verkehr[(df_Verkehr.Ubahn != \"\")]\n",
    "ubahn_grouped = df_Verkehr.groupby(['Ubahn'])['Betrag'].agg(['sum']).rename(columns={'sum': 'Total_Spendings'}).reset_index()\n",
    "\n",
    "print(ubahn_grouped.sort_values(by=\"Total_Spendings\",ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531da86",
   "metadata": {},
   "source": [
    "#### Task 7: New column through df.assign and replace white spaces with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Verkehr = df[(df.Politikbereich == \"Verkehr\")]\n",
    "\n",
    "out = (\n",
    "        df\n",
    "          .assign(UBahn= (df[\"Zweck\"].str.extract(\"(U\\s*\\d)\", expand=False)).str.replace(\" \", \"\")) \n",
    "          .groupby(\"UBahn\", as_index=False)[\"Betrag\"].sum()\n",
    "          .sort_values(by=\"Betrag\", ascending=False, ignore_index=True)\n",
    "       )\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317ee6cf",
   "metadata": {},
   "source": [
    "#### Task 7: Handling German U-Bahnlinie, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "verkehr= df[(df['Politikbereich']== 'Verkehr')]\n",
    "\n",
    "data = pd.concat([verkehr['Zweck'],verkehr['Betrag']], axis = 1)\n",
    "\n",
    "data['U-Bahn'] = data['Zweck'].copy()\n",
    "for k in range (0,849):\n",
    "    for i in range(9,0,-1):\n",
    "        if ((data['Zweck'].iloc[k]).find(f\"U {i}\") != -1):\n",
    "            data['U-Bahn'].iloc[k] = i\n",
    "        elif((data['Zweck'].iloc[k]).find(f'U{i}')!= -1):\n",
    "            data['U-Bahn'].iloc[k] = i\n",
    "        elif((data['Zweck'].iloc[k]).find(f'U-Bahnlinie {i}')!= -1):\n",
    "            data['U-Bahn'].iloc[k] = i\n",
    "   \n",
    "    if (  len(str(data['U-Bahn'].iloc[k]))!= 1 ):\n",
    "        data['U-Bahn'].iloc[k] = np.nan\n",
    "\n",
    "bahn = data[~data['U-Bahn'].isnull()]\n",
    "grouped = bahn.groupby(bahn['U-Bahn']).agg(['sum'])\n",
    "g_sort = grouped.sort_values(by=[('Betrag', 'sum')], ascending=False)\n",
    "\n",
    "g_sort[('Betrag', 'sum')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bc80f",
   "metadata": {},
   "source": [
    "#### Task 7: Sorting with lambda-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df[[\"Politikbereich\", \"Zweck\", \"Betrag\"]]\n",
    "df4 = df4.loc[df4[\"Politikbereich\"] == \"Verkehr\"]\n",
    "u_bahn = {}\n",
    "for i in range(1, 10):\n",
    "    u_bahn.update({\"U\" + str(i) : df4.loc[df4[\"Zweck\"].str.contains(\"u\" + str(i), case=False)][\"Betrag\"].sum()})\n",
    "\n",
    "for k, v in sorted(u_bahn.items(), key=lambda x: x[1], reverse=True): # every item in u_bahn is a tuple (label, cost)\n",
    "                                                                      # the lambda key selects the cost to sort by\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4f095",
   "metadata": {},
   "source": [
    "#### Task 7: Someone took the time to think if the results make sense :^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64873b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code sums up the expenditures of the U-Bahnlines. It doesn't just takes the first mentioned U-Bahnline into account but all mentioned\n",
    "money_usage = {}\n",
    "traffic = data_berlin[data_berlin[\"Politikbereich\"].str.match(\"Verkehr\")] # getting just the traffic data of Berlin\n",
    "\n",
    "for i in range(1,10): # loop over all U-Bahn U1-U9\n",
    "    str1 = \"U \" + str(i) # as the U-Bahnlines appear mostly as \"U 1\" or \"U1\" I construct both string appearances \n",
    "    str2 = \"U\" + str(i)\n",
    "    betrag = traffic[traffic[\"Zweck\"].str.contains(str1)][\"Betrag\"].sum() # getting the summed expenditures for \"U x\"\n",
    "    betrag += traffic[traffic[\"Zweck\"].str.contains(str2)][\"Betrag\"].sum() # getting the summed expenditures for \"Ux\"\n",
    "    money_usage.update({str2: betrag}) # connecting the money to the U-Bahn\n",
    "\n",
    "sorted_money = pd.DataFrame.from_dict(money_usage, orient='index', columns=['Betrag']) # making a pd-DF out of it for nice appearing and easy sorting \n",
    "sorted_money.sort_values(by=[\"Betrag\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a35eca",
   "metadata": {},
   "source": [
    "The order shown above makes more or less sense. The cheapest line is the U4 but with just 5 stations it's also the shortest and it is not so much frequented. The most expensive is the U5. This also makes sense as they just finished the part between Alexanderplatz and Hbf. The data was taken from the years before they did the construction. With freezing the soil below the Spree the whole work became a lot more expensive than planned. So the huge expenditure makes sense. I am a bit surprised that the U7 was so cheap as it is the longest line. I would have guessed that it might be among the more expensive ones. It also surprises me that the lines U1 and U3 differ so much even if they share the rails for quite some kilometers. But maybe they just used one line to take the expenditure even if it was for both. For the other lines it is difficult to evaluate as I am missing the expert knowledge. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
