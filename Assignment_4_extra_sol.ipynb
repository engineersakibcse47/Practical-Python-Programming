{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f75139",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "### A selection of interesting solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001b6b17",
   "metadata": {},
   "source": [
    "#### Task 5: A neat and well documented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5db2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(X, Y, iterations=100, eta=.1):\n",
    "    \n",
    "    # Initialize accuracy\n",
    "    acc = np.zeros(iterations)\n",
    "    \n",
    "    # find num of features\n",
    "    _, n_features = X.shape\n",
    "    \n",
    "    # Initialize weights\n",
    "    w = np.ones(n_features) / n_features\n",
    "    \n",
    "    # Initialize some help variables: \n",
    "    # correct_results_num - number of correct results per iteration; \n",
    "    # random_weight_corrected indicates that one random weight of \n",
    "    # a missclassified image per iteration is found\n",
    "    correct_results_num = 0\n",
    "    random_weight_corrected = False\n",
    "    \n",
    "    for it in range(1, iterations + 1):\n",
    "        # choose random idxs of the elements of X:  \n",
    "        for i in np.random.choice(np.arange(len(X)), size = len(X)):\n",
    "            \n",
    "            # sign(w.T*xi) - if w.T * xi more than 0 then 1, otherwise -1 \n",
    "            if np.dot(w.T, X[i]) > 0:\n",
    "                y_pred = 1\n",
    "            else: \n",
    "                y_pred = -1\n",
    "\n",
    "            # if predicted value equal practical value then add one \n",
    "            # more positive result, otherwise - correction of weights\n",
    "            if y_pred == Y[i]:\n",
    "                correct_results_num += 1\n",
    "            # correction of weights occures once per iteration\n",
    "            elif random_weight_corrected == False:\n",
    "                random_weight_corrected = True\n",
    "                w = w + eta / it * X[i] * Y[i]\n",
    "                \n",
    "        # Accuracy - number_correct_predictions / num_predictions\n",
    "        acc[it-1] = correct_results_num / len(X)\n",
    "        \n",
    "        # reset help variables \n",
    "        random_weight_corrected = False\n",
    "        correct_results_num = 0\n",
    "\n",
    "    # Return weights vector and accuracy\n",
    "    return w, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01afdd6",
   "metadata": {},
   "source": [
    "#### Task 5: Another neat solution. \n",
    "\n",
    "**Note**: the random seed is also a Hyperparameter, which people sometimes fine-tune via CV. Apart from the random initialization of the weights, the training process has more randomness to it (for instance, SGD also has some extra parameters like momentum). Try the code below for the digit **8**. You will notice that the algorithm will start at 100% accuracy, because the chosen seed is exactly right for that one case. With another seed, you would start at around 0 as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(X, Y, iterations=100, eta=.1):\n",
    "    \n",
    "    acc = np.zeros(iterations)\n",
    "    np.random.seed(2023)\n",
    "    \n",
    "    # Initialize weight vector\n",
    "    weights = np.random.rand(X.shape[1])\n",
    "    count = 0 # helper to calculate the acc (stores number of not correctly classified values)\n",
    "    \n",
    "    for it in range(100):\n",
    "        i = int(np.ceil(np.random.rand(1)*X.shape[0]))          # pick a random example\n",
    "        if np.sign(np.dot(weights.T, X[i])) != np.sign(Y[i]):   # check if correctly classified\n",
    "            weights = weights + eta/(it+1) * (X[i]*Y[i])        # update weights if not correct\n",
    "            count = count+1                                     # add one to number of wrong classified\n",
    "\n",
    "        acc[it] = 1-(count/(it+1))                              # calculate acc for every step\n",
    "    \n",
    "    print(\"Final Accuracy: \" + str(acc[it]) + \" after \" + str(it+1) + \" steps.\")        \n",
    "    # Return weight vector and accuracy\n",
    "    return weights, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7123cf",
   "metadata": {},
   "source": [
    "#### Task 5: Testing the random guess first\n",
    "\n",
    "**Note**: If we did this in the example above and checked the accuracy against a threshold, we could have decided that there is no training necessary at all for learning the digit **8** 8^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(X, Y, iterations=100, eta=.1):\n",
    "    \n",
    "    acc = np.zeros(iterations)\n",
    "    \n",
    "    # Initialize weight vector\n",
    "    weights = np.repeat(1/len(X[0]), len(X[0]))\n",
    "    \n",
    "    missclassified = [] #initalize missclassified examples \n",
    "    for k in range(len(X)):\n",
    "        if np.sign(sum(weights.T*X[k])) != Y[k]:\n",
    "            missclassified.append(k)\n",
    "    \n",
    "    #set accuracy for first iteration with 1/D weights\n",
    "    acc[0] = 1-(len(missclassified)/len(Y))\n",
    "    \n",
    "    for it in range(1, iterations):\n",
    "        correct = 0\n",
    "        m = np.random.randint(0, len(missclassified))  #pick a random index of missclassified example list\n",
    "        r = missclassified[m] #get index for X & Y of missclassified example \n",
    "\n",
    "        weights = weights + ((eta/(it)) * X[r]*Y[r]) #update weights with random missclassified example \n",
    "\n",
    "        missclassified = [] #update missclassified list \n",
    "        for i in range(len(Y)):\n",
    "            if np.sign(sum(weights.T*X[i])) != Y[i]:\n",
    "                missclassified.append(i) \n",
    "        \n",
    "        #count correct predictions with updated weights\n",
    "        correct_predictions = len(Y) - len(missclassified)\n",
    "        acc[iter] = correct_predictions/len(Y)\n",
    "\n",
    "    return weights, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da798a",
   "metadata": {},
   "source": [
    "#### Task 5: Extra investigation of misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d956d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digit_to_recognize = 3 # You can pick any other one from 0 to 9\n",
    "\n",
    "# Load the usps digits dataset from sklearn repository\n",
    "X, Y = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "Z = Y\n",
    "\n",
    "# Transform the 10-class labels into binary form\n",
    "y = np.sign((Y == digit_to_recognize)* 1.0 - .5)\n",
    "Y=y\n",
    "iterations=100\n",
    "eta=.1\n",
    "\n",
    "# if you want to watch at different iterations\n",
    "acc = np.zeros(iterations)# -99)\n",
    "\n",
    "num_features = X.shape[1]\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "# Initialize weight vector\n",
    "weights = np.random.randn(X.shape[1])\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    pred = []\n",
    "    num_correct = 0\n",
    "    for j in range(num_examples):\n",
    "        \n",
    "        est = np.dot(X[j], weights)\n",
    "        if est >= 0:\n",
    "            pred.append(True)\n",
    "            prediction = 1\n",
    "        else:\n",
    "            pred.append(False)\n",
    "            prediction = -1\n",
    "\n",
    "        if prediction == Y[j]:\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            weights += eta/(i+1.) * Y[j] * X[j]\n",
    "    acc_i = num_correct / num_examples\n",
    "\n",
    "    acc[i] = acc_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46977d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all digits that were predicted as \"3\": \n",
      " [3 3 3 9 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 7 3 3 3 3 3 3 8 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 9 3 3 3 3 3 3 3 3 3 3 3]\n",
      "index of missclassified digits: \n",
      " [  3  40  63  85  92 122 154 171]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAAD0CAYAAABKBsC6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEl0lEQVR4nO3dv6tXZQDH8XNKVBIcLAtEKkglIgInQYgIl7ag5gKXfkzh0OAUDRGOLUp/gIGjm8vdvS0NEUE5qA1RkoFyoYw6rQ1XUeo+9/u212s9Bz7Pd3hzvtszL8syAV2PbPcBgH9HxBAnYogTMcSJGOJEDHEihjgRQ5yIIW7Hg7y8c9617J72bNVZtt2dA2N/24tP3Bi6N9rXv+4furfrh42heyP9Nm1Md5bf582ePVDEu6c907H5xH9zqhV0/d3jQ/e+fOfs0L3Rnrvw3tC9Q6cuD90baX1Zu+szf6chTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghbl6W5b5f3jvvWx7mGyDe//7K0L2Lvxwdunf19r6hex88e/dbC7bCucOHhu6NtL6sTbeWm5te4+JLDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ9yO7T7AKvns6th7pj4/8sXQvSNP7xm6d/L6y0P3pun24L3V4EsMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnLuY/mHj/IGxgx+Pnfvuj42he1fOvDB077FpfejeqvAlhjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ5yIIW5eluW+X94771uOzSe28Dj/L3+9cnTo3sEzV4buvf74V0P3zh0+NHRvpPVlbbq13Jw3e+ZLDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ9yO7T7AvTz61JND966d3T907+CbY+8qunzp+NC90ycvDd2bpof3LqZ78SWGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSJGOJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghbqXvYhrtk5cuDt376NTbQ/feemNt6N6nP742dG+abg/eWw2+xBAnYogTMcSJGOJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYogTMcSt9F1Mf/7089C90+fH3o307Ydnh+6N9uo3zw/d2+kuJqBIxBAnYogTMcSJGOJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4kQMcSKGOBFDnIghTsQQJ2KIEzHEiRjiRAxxIoY4EUOciCFOxBAnYoibl2W5/5fn+cY0Tde27jjAXTyzLMv+zR48UMTA6vF3GuJEDHEihjgRQ5yIIU7EECdiiBMxxIkY4v4GUEtoonx36OIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missclassified_idx = np.where(Z[pred]!=digit_to_recognize)[0]\n",
    "\n",
    "# choose which idx/number to check (0 to len(missclassified_idx))\n",
    "watch_misclas_idx = missclassified_idx[-1] # <-- here\n",
    "\n",
    "X, Y = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "try:\n",
    "    plt.matshow(X[np.where(pred)[0][watch_misclas_idx],:].reshape(8,8))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "except:\n",
    "    print(\"no missclassified values!\")\n",
    "print(f\"all digits that were predicted as \\\"{digit_to_recognize}\\\": \\n {Z[pred]}\")\n",
    "print(f\"index of missclassified digits: \\n {missclassified_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16df825",
   "metadata": {},
   "source": [
    "#### Task 5: Train only until a desired metric level is reached.\n",
    "\n",
    "This what people actually do in practice: they check several metrics during training, so that they know in time if their algorithm has already converged. You don't want to train for 100 epochs, if you are already good enough after the first 10 epochs. On the contrary, you may run the risk that your SGD wanders off towards a suboptimal solution if you train for too long. In ML, this is called **Early Stopping**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25774d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(x, y, iterations=100, eta=.1):\n",
    "    \n",
    "    # Initialize weight vector\n",
    "    weights = np.random.rand(x.shape[1])\n",
    "\n",
    "    iteration = 0\n",
    "    accuracy = 0\n",
    "    acc = list()\n",
    "        \n",
    "    # Repeat until maximum number of iterations or desired accuracy is reached\n",
    "    while (iteration <= iterations) and (accuracy <= 0.999):\n",
    "        \n",
    "        total_error = 0\n",
    "        \n",
    "        # Repeat for every line\n",
    "        for i in range(x.shape[0]):\n",
    "                \n",
    "            # Predict the label (1 or -1) of x[i] using the weights    \n",
    "            label = 1 if weights @ x[i] >= 0 else -1\n",
    "            \n",
    "            # Update the weights of the perceptron only if x[i] is misclassified by y[i]\n",
    "            if label != y[i]:\n",
    "                weights = weights - (eta/(i+1.) * np.array([label*value for value in x[i]]))\n",
    "                total_error += 1\n",
    "\n",
    "        # Calculate accuracy and add it to list of accuracies \"acc\"\n",
    "        accuracy = 1 - total_error/len(x)\n",
    "        acc.append(accuracy)\n",
    "        iteration += 1\n",
    "              \n",
    "    # Return weight vector and accuracy\n",
    "    return weights, acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
