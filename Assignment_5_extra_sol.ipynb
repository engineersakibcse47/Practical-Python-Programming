{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448c727f",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "### A selection of interesting solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7af61",
   "metadata": {},
   "source": [
    "#### Task 2: one-hots via pandas get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c3000e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green  red  yellow\n",
       "0     1      0    0       0\n",
       "1     0      1    0       0\n",
       "2     0      0    1       0\n",
       "3     0      0    0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['blue', 'yellow', 'blue', 'green', 'red', 'yellow']\n",
    "\n",
    "def one_hot_encoding(string_list):\n",
    "\n",
    "    m=len(string_list)\n",
    "    n=np.unique(string_list, return_counts=False)\n",
    "    \n",
    "    y = pd.get_dummies(n)\n",
    "    \n",
    "    coding=[y.loc[:,x].tolist() for x in string_list]\n",
    "    \n",
    "    return y, coding\n",
    "\n",
    "y, one_hot_encoded_data = one_hot_encoding(data)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1224bd",
   "metadata": {},
   "source": [
    "#### Task 2: double/nested list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb35a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['blue', 'yellow', 'blue', 'green', 'red', 'yellow']\n",
    "\n",
    "def one_hot_encoding(string_list):\n",
    "    \"\"\"\n",
    "    This function takes list of strings and does a one hot encoding of it after sorting it alphabetically. \n",
    "    The function is derived from the quiz of the 4. January 2023\n",
    "    \n",
    "    param: string_list\n",
    "    return: list of lists with the one_hot_encoding\n",
    "    \"\"\"\n",
    "    unique_items = sorted(list(set(string_list)))\n",
    "    print(unique_items)\n",
    "    one_hot = [[1 if ui == w else 0 for ui in unique_items] for w in string_list]\n",
    "\n",
    "    return(one_hot)\n",
    "\n",
    "one_hot_encoded_data = one_hot_encoding(data)\n",
    "one_hot_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce745e",
   "metadata": {},
   "source": [
    "#### Task 3: Very neat solution with lots of built-in Python data structures and operations i.e. filter, map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def bag_of_words(corpus):\n",
    "    # Perform pre-processing on the input text to remove non-alphanumeric characters and convert to lowercase\n",
    "    pre_process = lambda x: \"\".join(filter(str.isalnum, x.lower()))\n",
    "    # Tokenize the input text\n",
    "    tokens = [[pre_process(n) for n in i.split()] for i in corpus]\n",
    "    # Count the occurrences of each token in the tokenized text\n",
    "    token_counts = list(map(Counter, tokens))\n",
    "    # Get the unique words in the text\n",
    "    unique_words = sorted(set([word for tokens in tokens for word in tokens]))\n",
    "    # Create a dataframe with the token counts as the values and the unique words as the columns\n",
    "    result = pd.DataFrame(token_counts, columns=unique_words).fillna(0).astype(int)\n",
    "    return list(result.columns), np.array(result.values)\n",
    "\n",
    "bag_of_words(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8dfcf7",
   "metadata": {},
   "source": [
    "#### Task 3: regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "def bag_of_words(corpus):\n",
    "\n",
    "    words = list(set(re.split('[^a-z]', ''.join(corpus).lower())))\n",
    "    words.remove('')\n",
    "    print(words)\n",
    "    wordfreq = [[re.split('[^a-z]', sentences.lower()).count(p) for p in words] for sentences in corpus]\n",
    "    return np.array(wordfreq)\n",
    "bag_of_words(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c37f9",
   "metadata": {},
   "source": [
    "#### Task 5: comprehension and zipped arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b13a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_predicted):\n",
    "    # zip for parallel variables\n",
    "    tp = sum([1 for yt, yp in zip(y_true, y_predicted) if yt == 1 and yp == 1])\n",
    "    fp = sum([1 for yt, yp in zip(y_true, y_predicted) if yt == 0 and yp == 1])\n",
    "\n",
    "    return tp / (tp + fp) if tp + fp != 0 else 0\n",
    "\n",
    "print(precision(np.array([1,0,1,1]), np.array([1,1,0,0])))\n",
    "\n",
    "def recall(y_true, y_predicted):\n",
    "    tp = sum([1 for yt, yp in zip(y_true, y_predicted) if yt == 1 and yp == 1])\n",
    "    fn = sum([1 for yt, yp in zip(y_true, y_predicted) if yt == 1 and yp == 0])\n",
    "\n",
    "    return tp / (tp + fn) if tp + fn != 0 else 0\n",
    "\n",
    "print(recall(np.array([1,0,1,1]), np.array([1,1,0,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3d511",
   "metadata": {},
   "source": [
    "#### Task 5: alternative compact solution using the intersection operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_predicted):\n",
    "    # Count the number of true positives\n",
    "    true_positives = np.sum((y_true == 1) & (y_predicted == 1))\n",
    "    # Count the number of false positives\n",
    "    false_positives = np.sum((y_true == 0) & (y_predicted == 1))\n",
    "    # Calculate precision\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    # If precision is NaN (e.g. when true_positives and false_positives are both 0), return 0\n",
    "    return precision if not np.isnan(precision) else 0\n",
    "\n",
    "def recall(y_true, y_predicted):\n",
    "    # Count the number of true positives\n",
    "    true_positives = np.sum((y_true == 1) & (y_predicted == 1))\n",
    "    # Count the number of false negatives\n",
    "    false_negatives = np.sum((y_true == 1) & (y_predicted == 0))\n",
    "    # Calculate recall\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    # If recall is NaN (e.g. when true_positives and false_negatives are both 0), return 0\n",
    "    return recall if not np.isnan(recall) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23558837",
   "metadata": {},
   "source": [
    "#### Task 5: insanely neat and carefully thought-through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d1ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def input_check(y_true: np.ndarray, y_predicted: np.ndarray) -> None:\n",
    "    \"\"\"Overly verbose check of y_true and y_predicted numpy array for precision\n",
    "    and recall calculations. The arrays must be numpy arrays and of shape (n,),\n",
    "    where n denotes the length of the input arrays. The array values must be\n",
    "    binary (i.e. 0 or 1).\n",
    "    Args:\n",
    "        y_true (np.ndarray): y_true array\n",
    "        y_predicted (np.ndarray): y_predicted array\n",
    "    Raises:\n",
    "        TypeError: If arguments are not of type np.ndarray\n",
    "        ValueError: In case of unequal input array shape, if y_true is not\n",
    "            1-dimensional, or if input arrays are not binary.\n",
    "    \"\"\"\n",
    "\n",
    "    # type check y_true\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        raise TypeError(\n",
    "            f'For y_true expected np.ndarray type, got {type(y_true)}.')\n",
    "    \n",
    "    # type check y_predicted\n",
    "    if not isinstance(y_predicted, np.ndarray):\n",
    "        raise TypeError(\n",
    "            f'For y_predicted expected np.ndarray type, got {type(y_predicted)}.')\n",
    "\n",
    "    # shape comparison\n",
    "    if not y_true.shape == y_predicted.shape:\n",
    "        raise ValueError(\n",
    "            'y_true and y_predicted array are not of same shape. This is forbidden.')\n",
    "\n",
    "    # shape must be of length 1 (1d-array)\n",
    "    if len(y_true.shape) != 1:\n",
    "        raise ValueError('y_true is not a 1d array. This is forbidden.')\n",
    "\n",
    "    # check if arrays are binary (https://stackoverflow.com/a/40597324/12785394)\n",
    "    if not np.array_equal(y_true, y_true.astype(bool)):\n",
    "        raise ValueError('y_true is not binary. This is forbidden.')\n",
    "\n",
    "    if not np.array_equal(y_predicted, y_predicted.astype(bool)):\n",
    "        raise ValueError('y_predicted is not binary. This is forbidden.')\n",
    "\n",
    "\n",
    "def precision(y_true: np.ndarray, y_predicted: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the precision of a binary prediction:\n",
    "    precision = tp / (tp + fp), with the true positives tp and the false\n",
    "    positives fp.\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels (1->positive, 0->negative)\n",
    "        y_predicted (np.ndarray): Predicted labels (1->positive, 0->negative)\n",
    "    Returns:\n",
    "        float: Calculated precision\n",
    "    \"\"\"\n",
    "    # Nesting the input_check in the try except block is somewhat redundant,\n",
    "    # but it still shows that we expect an error to occur here and might\n",
    "    # refine the error catching in the future...\n",
    "    try:\n",
    "        input_check(y_true, y_predicted)\n",
    "    except Exception:\n",
    "        raise\n",
    "    \n",
    "    # calculate the true positives tp\n",
    "    # no need here for eg y_true==1 as we already know that our input is binary\n",
    "    tp = np.sum(y_true & y_predicted)\n",
    "\n",
    "    # calculate the false positives fp\n",
    "    fp = np.sum((y_true == 0) & y_predicted)\n",
    "\n",
    "    # calculate the denominator beforehand for 0 division catch\n",
    "    denominator = tp + fp\n",
    "\n",
    "    if denominator:\n",
    "        return tp / denominator\n",
    "    \n",
    "    else:\n",
    "        # divide by 0 case\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall(y_true: np.ndarray, y_predicted: np.ndarray) -> float:\n",
    "    \"\"\"Calculate the recall of a binary prediction:\n",
    "    precision = tp / (tp + fn), with the true positives tp and the false\n",
    "    negatives fn.\n",
    "    Args:\n",
    "        y_true (np.ndarray): True labels (1->positive, 0->negative)\n",
    "        y_predicted (np.ndarray): Predicted labels (1->positive, 0->negative)\n",
    "    Returns:\n",
    "        float: Calculated recall\n",
    "    \"\"\"\n",
    "    \n",
    "    # perform input checks\n",
    "    try:\n",
    "        input_check(y_true, y_predicted)\n",
    "    except Exception:\n",
    "        raise\n",
    "    \n",
    "    # calculate the true positives tp\n",
    "    tp = np.sum(y_true & y_predicted)\n",
    "    \n",
    "    # calculate the false negatives fn\n",
    "    fn = np.sum(y_true & (y_predicted == 0))\n",
    "\n",
    "    # calculate the denominator beforehand for 0 division catch\n",
    "    denominator = tp + fn\n",
    "\n",
    "    if denominator:\n",
    "        return tp / denominator\n",
    "    else:\n",
    "        # divide by 0 case\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf644baf",
   "metadata": {},
   "source": [
    "#### Task 6: function defined in inner scope of an outer function; the inner one is then applied on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/bundestags_parlamentsprotokolle.csv.gzip'\n",
    "PATH_STOPWORDS = 'data/stopwords.txt'\n",
    "\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a pd.DataFrame with the requested government column from the\n",
    "    csv file containing parliament speeches.\n",
    "    Args:\n",
    "        path (str): path to the compressed csv file\n",
    "    Returns:\n",
    "        pd.DataFrame: With government column extended DataFrame containing \n",
    "            parliament speeches.\n",
    "    \"\"\"\n",
    "\n",
    "    # load from compressed csv file, already contains index col at position 0\n",
    "    df = pd.read_csv(PATH, compression='gzip', index_col=0)\n",
    "\n",
    "    def categorizer(row) -> bool:\n",
    "        \"\"\"Categorizer for pd.apply. Returns True if party belongs to\n",
    "        government, otherwise returns False.\n",
    "        \"\"\"\n",
    "        if row['wahlperiode'] == 17:\n",
    "            if row['partei'] in ('cducsu', 'fdp'): return True\n",
    "            else: return False\n",
    "        \n",
    "        elif row['wahlperiode'] == 18:\n",
    "            if row['partei'] in ('cducsu', 'spd'): return True\n",
    "            else: return False\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Invalid value in column 'wahlperiode'.\")\n",
    "\n",
    "    # apply the categorizer row-wise, creating the column 'government'\n",
    "    df['government'] = df.apply(categorizer, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c24887",
   "metadata": {},
   "source": [
    "#### Task 6: Data loading routine using lambda, Random Search (instead of Grid Search), Stratified k-fold (so that the classes are balanced throughout all the folds)\n",
    "\n",
    "*Note*: the metrics report after each fold are fairly misleading, since they show 1.0 precision, recall and accuracy. The final report is sensible though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e06921",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function to extend the column \"government\" in the dataframe.'''\n",
    "def Government_True_Or_False(Tempwahlperiode,Temppartei):\n",
    "    if Tempwahlperiode == 17 and (Temppartei == 'cducsu' or Temppartei == 'fdp'): # if the party is cducsu or fdp and the wahlperiode is 17, then the value is True\n",
    "        return True\n",
    "    elif Tempwahlperiode == 18 and (Temppartei == 'cducsu' or Temppartei == 'spd'): # if the party is cducsu or spd and the wahlperiode is 18, then the value is True\n",
    "        return True\n",
    "    else:\n",
    "        return False # otherwise the value is False\n",
    "\n",
    "'''Function that loads the dataset into a dataframe and adds the column \"government\" to the dataframe by calling the function Government_True_Or_False.'''\n",
    "DATADIR = \"data\"\n",
    "def load_data():\n",
    "    DF = pd.read_csv(DATADIR + '/bundestags_parlamentsprotokolle.csv').drop('Unnamed: 0',axis=1) # load the dataset into a dataframe\n",
    "    DF['government'] = DF.apply(lambda row: Government_True_Or_False(row['wahlperiode'],row['partei']),axis=1) # add the column \"government\" to the dataframe\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1333982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bundestag(df):\n",
    "    # Initialize Pipeline for extracting features\n",
    "    # Define Hyperparameters and HPO strategy\n",
    "    # Split training + test\n",
    "    # Train model\n",
    "    # Run predictions and print scores\n",
    "\n",
    "    #Label encode the column \"sprecher\"\n",
    "    le = LabelEncoder()\n",
    "    df['sprecher'] = le.fit_transform(df['sprecher']) # label encode the column \"sprecher\"\n",
    "    df['partei'] = le.fit_transform(df['partei']) # label encode the column \"partei\"\n",
    "\n",
    "    #Count vectorizer\n",
    "    df.text = df.text.astype(str).str.lower() # convert the column \"text\" to lower case\n",
    "    AllText = df.text.tolist() # convert the column \"text\" to a list\n",
    "    hv = HashingVectorizer(n_features=20) # initialize the hashing vectorizer\n",
    "    Vectors = hv.fit_transform(AllText).toarray().tolist() # fit the hashing vectorizer to the list and convert the result to a list\n",
    "    df[['vectorized Text '+str(i) for i in range(20)]] = pd.DataFrame(Vectors, index= df.index) # add the list to the dataframe\n",
    "    df = df.drop('text',axis=1) # drop the column \"text\"\n",
    "\n",
    "    #Hyperparameter optimization\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 50, stop = 150, num = 10)]\n",
    "    max_features = ['sqrt']\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'n_jobs':[-1]\n",
    "                  }\n",
    "\n",
    "    #Splitting the data\n",
    "    X = df.drop('government',axis=1)\n",
    "    y = df['government']\n",
    "\n",
    "\n",
    "    #Split data bases upon wahlperiode value counts\n",
    "    wahlperiode_17 = df[df['wahlperiode'] == 17]\n",
    "    wahlperiode_18 = df[df['wahlperiode'] == 18]\n",
    "\n",
    "    X = wahlperiode_17.drop('government',axis=1)\n",
    "    y = wahlperiode_17['government']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    #Random forest classifier\n",
    "    rf = RandomForestClassifier()\n",
    "    #Randomized search cross validation\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 6, cv = 2, verbose=1, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    BestParams = rf_random.best_params_\n",
    "    print('Hyperparameter Optimization finished.')\n",
    "\n",
    "    # Stratified K-Fold\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    Val = 0\n",
    "    # Training the model\n",
    "    print(\"Results on 17 Bundestag:\")\n",
    "    for train_index, test_index in skf.split(X_train, y_train): # split the training data into training and validation data\n",
    "        Val += 1\n",
    "        TX_train, TX_test = X_train.iloc[train_index, :], X_train.iloc[test_index, :]\n",
    "        Ty_train, Ty_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        rf = RandomForestClassifier(**BestParams)\n",
    "        rf.fit(TX_train,Ty_train)\n",
    "        y_pred = rf.predict(TX_test)\n",
    "        # Print scores\n",
    "        print('Fold Number: ',Val)\n",
    "        print('Precision: ',precision(Ty_test,y_pred))\n",
    "        print('Recall: ',recall(Ty_test,y_pred))\n",
    "        print(classification_report(Ty_test,y_pred))\n",
    "        print()\n",
    "\n",
    "    X = wahlperiode_18.drop('government',axis=1)\n",
    "    y = wahlperiode_18['government']\n",
    "\n",
    "    print(\"Results on 18 Bundestag:\")\n",
    "    y_pred = rf.predict(X)\n",
    "    # Print scores\n",
    "    print('Precision: ',precision(y,y_pred))\n",
    "    print('Recall: ',recall(y,y_pred))\n",
    "    print(classification_report(y,y_pred))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
